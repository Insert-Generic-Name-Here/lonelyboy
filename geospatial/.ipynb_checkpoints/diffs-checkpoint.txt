diff --git a/geospatial/preprocessing.py b/geospatial/preprocessing.py
index 6cc97cc..1b537e3 100644
--- a/geospatial/preprocessing.py
+++ b/geospatial/preprocessing.py
@@ -49,6 +49,7 @@ def resample_geospatial(vessel, rule = '60S', method='linear', crs = {'init': 'e
 	#resample and interpolate using the method given. Linear is suggested
 	upsampled = vessel.resample(rule,on='datetime', loffset=True, kind='timestamp').first()
 	interpolated = upsampled.interpolate(method=method)
+	interpolated['real_point'] = interpolated.datetime.apply(lambda x: 1 if type(x)==pd._libs.tslibs.timestamps.Timestamp else 0)    
 	#interpolate the geom column with the correct point objects using lat and lon
 	interpolated['geom'] = interpolated[['lon', 'lat']].apply(lambda x: Point(x[0], x[1]), axis=1)
 	# reset the index to normal and use the old index as new timestamp
@@ -145,8 +146,8 @@ def detect_POIs(df, feature='velocity', alpha=20, window=100):
 		pois = [0,outlier_groups[0]]
 		#if a point is not a part of a concecutive list add it to the poi list
 		#that way only the first point of every group of outliers will be concidered a POI
-		for ind, point in enumerate(outlier_groups[1:],1):
-			if point != outlier_groups[ind-1]+1:
+		for ind, point in enumerate(outlier_groups[1:-1],1):
+			if (point != outlier_groups[ind-1]+1) or (point != outlier_groups[ind+1]-1):
 				pois.append(point)
 		pois.append(len(df)-1)
 	except : # No Outliers?! Maybe you Need to Tune the Function's Parameters
@@ -154,17 +155,6 @@ def detect_POIs(df, feature='velocity', alpha=20, window=100):
 	return pois, (qlow, qhigh)
 
 
-
-def get_trajetory_segment(x, pois):
-	#THIS IS STUPID STUPID ...STUPIDSTUPID DESIGN
-	#TODO
-	for poi in pois:
-		if x.name > poi:
-			if poi == pois[-1]: print('prob')
-			continue
-		return int(pois.index(poi)-1)
-
-
 def segment_trajectories(gdf,pois_alpha=80, pois_window=100, n_jobs=1, np_split=True, feature='mmsi'):
 	cores = _get_n_jobs(n_jobs)
 	if cores==1:
@@ -179,18 +169,16 @@ def segment_trajectories(gdf,pois_alpha=80, pois_window=100, n_jobs=1, np_split=
 
 def detect_POIs_approx(vessel, window):
 	lst = []
-	alpha = 1
+	alpha = 1e+5
 	while True:
 		lst.append(tuple(detect_POIs(vessel, alpha=alpha, window=window)[0]))
 		pois, freq = Counter(lst).most_common(1)[0]
-		print(alpha, len(pois))
-		if len(lst[-1]) == 2 or alpha>=500:
-			print(pois)
+		if len(lst[-1]) == 2 or alpha>=1e+10:
 			return pois
-		alpha += 1
+		alpha += 1e+8
 
 
-def _segment_vessel(vessel, ports,pois_alpha, pois_window):
+def _segment_vessel(vessel, ports,pois_alpha, pois_window, semantic=False):
 	vessel.reset_index(drop=True, inplace=True)
 	if len(vessel) == 1 :
 		vessel.traj_id  = 0.0
@@ -209,17 +197,18 @@ def _segment_vessel(vessel, ports,pois_alpha, pois_window):
 	# semantic_id = 2 -> Accelerating
 	# semantic_id = 3 -> Decelerating
 	for i in range(len(pois)-1):
-		slice = vessel.iloc[pois[i]:pois[i+1]]
-		if slice.velocity.mean()<1:
-			if slice['geom'].apply(lambda x: distance_to_nearest_port(x, ports)).mean()<=0.1:
-				vessel.loc[pois[i]:pois[i+1], 'semantic_id'] = 0
+		if semantic:
+			slice = vessel.iloc[pois[i]:pois[i+1]]
+			if slice.velocity.mean()<1:
+				if slice['geom'].apply(lambda x: distance_to_nearest_port(x, ports)).mean()<=0.1:
+					vessel.loc[pois[i]:pois[i+1], 'semantic_id'] = 0
+				else:
+					vessel.loc[pois[i]:pois[i+1], 'semantic_id'] = 1
 			else:
-				vessel.loc[pois[i]:pois[i+1], 'semantic_id'] = 1
-		else:
-			if slice.velocity.diff().mean()<0:
-				vessel.loc[pois[i]:pois[i+1], 'semantic_id'] = 3
-			else:
-				vessel.loc[pois[i]:pois[i+1], 'semantic_id'] = 2
+				if slice.velocity.diff().mean()<0:
+					vessel.loc[pois[i]:pois[i+1], 'semantic_id'] = 3
+				else:
+					vessel.loc[pois[i]:pois[i+1], 'semantic_id'] = 2
 		vessel.loc[pois[i]:pois[i+1], 'traj_id'] = i
 	vessel['pois'] = [pois]*len(vessel)
 	return vessel
@@ -321,3 +310,23 @@ def parallelize_dataframe(df, func, np_split=False, feature='mmsi', num_partitio
 	 pool.close()
 	 pool.join()
 	 return df
+
+
+def _pipeline_apply(vessel, ports, velocity_window=3, velocity_drop_alpha=3, smoothing=True, res_rule = '60S', res_method='linear', crs = {'init': 'epsg:4326'}, drop_lon_lat = False, resampling_first=True, drop_outliers=False, pois_alpha=-1, pois_window=100, semantic=False ):
+	vessel.drop_duplicates(['ts'], inplace=True)
+	vessel.reset_index(inplace=True, drop=True)
+	vessel.drop(['id', 'status'], axis=1, inplace=True, errors='ignore')
+	vessel['geom'] = vessel[['lon', 'lat']].apply(lambda x: Point(x[0],x[1]), axis=1)
+	vessel=  gpd.GeoDataFrame(vessel, geometry='geom')
+	vessel = _resample_and_calculate_velocity_vessel(vessel, velocity_window, velocity_drop_alpha, smoothing, res_rule, res_method, crs, drop_lon_lat, resampling_first, drop_outliers)
+	vessel = _segment_vessel(vessel, ports, pois_alpha, pois_window, semantic)
+	return vessel
+
+
+def resample_and_segment(vessel, ports, pre_segment_threshold=12, velocity_window=3, velocity_drop_alpha=3, smoothing=True, res_rule = '60S', res_method='linear', crs = {'init': 'epsg:4326'}, drop_lon_lat = False, resampling_first=True, drop_outliers=False, pois_alpha=-1, pois_window=100, semantic=False):
+	if pre_segment_threshold != 0:
+		dfs = np.split(vessel, vessel.ts.diff(-1).abs().index[vessel.ts.diff()>60*60*pre_segment_threshold])
+		df_fn = pd.concat([_pipeline_apply(df, ports, velocity_window, velocity_drop_alpha, smoothing, res_rule, res_method, crs, drop_lon_lat, resampling_first, drop_outliers, pois_alpha, pois_window, semantic) for df in dfs if len(df)>1])
+	else:
+		df_fn = _pipeline_apply(vessel, ports, velocity_window, velocity_drop_alpha, smoothing, res_rule, res_method, crs, drop_lon_lat, resampling_first, drop_outliers, pois_alpha, pois_window, semantic)
+	return df_fn
\ No newline at end of file
